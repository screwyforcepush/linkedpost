{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fixes a bug with asyncio and jupyter\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "from langchain.document_loaders.sitemap import SitemapLoader\n",
    "sitemap_loader = SitemapLoader(web_path=\"https://python.langchain.com\")\n",
    "\n",
    "docs = sitemap_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://netflixtechblog.com/data-ingestion-pipeline-with-operation-management-3c5c638740a8\"]\n",
    "import os\n",
    "from langchain.document_loaders import DiffbotLoader\n",
    "loader = DiffbotLoader(urls=urls, api_token=\"10f1f90cfba4a5ad3dddc8f3057f37f3\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAN\n",
    "* save each step as structured JSON\n",
    "* latest research \n",
    "* -> brainstorm 3 applications that could be applied to video streaming industry\n",
    "* -> search web to score each idea novel application, feasibility.\n",
    "* -> select best candidtate \n",
    "* -> enrich with ai research with sources and video streaming analytics db\n",
    "* -> solution design requirements\n",
    "* -> Skeleton solution design document from requirements and idea\n",
    "* -> break down into steps document (blocks) for each step do:  BABYAGI??\n",
    "* -> solution design from ai eng, analytics and web. Completed, incomplete, and current step as context.\n",
    "* -> Compile and review against requirements\n",
    "* -> get more info for each feedback point\n",
    "* -> apply fix formatted with headings\n",
    "* -> group into meaningful headings subheadings with how-to blog context\n",
    "* -> apply content grouping to remove duplication\n",
    "\n",
    "<!-- \n",
    "DO NOT NEED TO IMPLEMENT SOLUTION DESIGN IS SUFFECIENT FOR AUDIENCE\n",
    "* -> plan end to end implementation\n",
    "* -> end to end implementation documentation from ai eng, analytics and web\n",
    "* -> review and suggest improvements by ai, video and business experts -> adjust based on feedback using pinecone and web -->\n",
    "* -> alex persona turn into a blog post done\n",
    "* -> 2 research paper sources from idea key technologies.\n",
    "* -> reference sources in introduction\n",
    "* -> social media manager optimise linkedin post\n",
    "* -> image generarion + sources\n",
    "* -> linkedin and medium publish\n",
    "\n",
    "Next itteration\n",
    "* Sources?\n",
    "* idea creator baby agi PM. not needed?\n",
    "* multiple brainstorm runs and combine similar\n",
    "* multiple scoring runs from diff perspectives\n",
    "\n",
    "# TODO\n",
    "* plan and execute orchestration - cant use openai function for now for execute. perhaps this could be some chain routing\n",
    "* MultiQueryRetriever - done\n",
    "* tone analysis from my writing - done\n",
    "* need more tech documentation for implementation, metric formulas. - done\n",
    "* chain routing - ai research for cache warm -> unique connection -> video streaming application -> implementation agent -> social post agent\n",
    "* idea generation - papers of the week abstracts. BRAINSTORMER prompt\n",
    "\n",
    "\n",
    "# Data\n",
    "\n",
    "Deprio\n",
    "* https://ai.googleblog.com/search/label/AI?max-results=11&m=1\n",
    "* https://www.deeplearning.ai/the-batch/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Other content I have written\n",
    "* streaming service statistics and news\n",
    "* amplitude\n",
    "* ad moat and video metrics\n",
    "* entertainment science\n",
    "\n",
    "# My draft plan\n",
    "1. Create datasets of: \n",
    "AI research, done papers\n",
    "AI tutorials, \n",
    "AI news, \n",
    "AI engineering, done langchain\n",
    "video metrics, done jump, brightcove\n",
    "ad metrics, todo moat\n",
    "streaming service blog posts, \n",
    "user behavior analysis methods, \n",
    "entertainment science, \n",
    "audience, \n",
    "discord threads,\n",
    "2. Prompt generative AI make connections between these datasets in a unique way. Providing execution examples.\n",
    "3. Verify that this is a novel approach via search.\n",
    "4. Create and post linkedin post from the content\n",
    "5. Automate the entire process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
