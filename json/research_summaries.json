[
    {
        "seed": "",
        "summaries": [
            " Chain of thought can be implemented as a prompt by using language models to enable complex reasoning. This is done by prompting with least-to-most prompting and using deep-CoT and shallow-CoT with a \u03be value. The accuracy of the datasets can be tested by using the Correct-CoT and Wrong-CoT models. The exemplars are selected on AQuA train set and can be used to test the accuracy of the models."
        ]
    },
    {
        "seed": "what makes tree of thought a unique prompting technique?",
        "summaries": [
            " Automating generative AI can be done through various platforms such as Replit, Jupyter Notebook, Microsoft AI Builder, Zapier, Superbio.ai, Github Copilot, Replit Ghostwriter, and AI learning experiences for K-12. It is important to consider ethical issues when using AI, and there are various curricula available to promote AI literacy for middle school students."
        ]
    },
    {
        "seed": "explain prompt engineering",
        "summaries": [
            "\n\nPrompt engineering is the process of creating prompts to generate text or images. It involves analysing the text or images generated by the prompts to determine their aesthetic appeal. Mark Weiser's 1993 paper on ubiquitous computing is a key reference in this field. Yutong Xie et al. (2023) and Fred Zenker and Kristopher Kyle (2021) have conducted research on prompt engineering, and Joanna Zylinska (2020) has written a book on AI art.",
            " Prompt logs are used in text-to-image generation systems to impact the quality of the generated images. Patterns and trends in the prompt logs can lead to better or worse image generation. Research has been conducted to investigate minimum text lengths for lexical diversity indices, variable length video generation from open domain textual descriptions, a large-scale prompt gallery dataset for text-to-image generative models, and design guidelines for prompt engineering text-to-image generative models.",
            " Prompt logs have an impact on the performance of text-to-image generation systems in terms of aesthetic appeal. Specific prompts or patterns in prompt logs can lead to high aesthetic appeal images. These findings can be compared to the impact of prompt logs on other language models, such as text classification or data visualization models."
        ]
    },
    {
        "seed": "How can we recreate dreams using generative AI?",
        "summaries": [
            " Generative AI can be used to recreate dreams by using a combination of text-to-image generation, latent diffusion models, and AI+ ethics curricula. This technology can be used to create immersive experiences and can be applied to a variety of fields, such as education, art, and storytelling. Additionally, ethical considerations must be taken into account when using this technology.",
            " AI curricula for middle school students should address key ethical considerations such as inclusivity, accessibility, and safety. These considerations can be integrated into the technical learning and career futures of the students by developing AI+ ethics curricula, exploring narrative-driven curriculum, and designing AI learning experiences with a design framework. Potential applications of AI in the arts education of disabled young people include identity construction environments, zero-shot text-to-image generation, and high-resolution image synthesis.",
            " AI can be used to support the arts education of disabled young people by providing tailored learning experiences and tools to help them engage with the arts. Potential challenges include ensuring inclusivity and accessibility, as well as ethical considerations such as privacy and data protection. To address these challenges, AI-based solutions should be designed with the needs of disabled young people in mind and should take into account the ethical implications of their use.",
            "The abstract does not provide specific information related to the given prompt about the impact of AI-generated art on emerging art scenes like Alien Dreams or whether it can be considered a new form of creativity or merely a tool for artists. The abstract includes references to various studies and projects related to AI programming, ethics, and education, as well as specific AI-generated art projects such as Make-A-Video and Phenaki. The abstract also mentions the use of AI in text-to-image generation and image inpainting. Overall, the abstract provides a broad overview of various topics related to AI and its applications, but does not directly address the given prompt.",
            "- Developing AI curricula for middle school students requires ethical considerations.\n- These considerations can be integrated into the curriculum through project-based learning and narrative-driven approaches.\n- The curriculum should aim to promote AI literacy while also addressing ethical issues such as bias, privacy, and accountability.\n- Identity construction environments and virtual cities can be used to develop personal and moral values in students.\n- The curriculum should also consider the diversity of students and address stereotypes and biases.",
            "The abstract does not provide information specifically related to the question prompt about AI-generated art and its challenges to traditional aesthetics or potential applications. Instead, it lists various academic articles and preprints related to AI programming, ethics, and education. Some of the articles mentioned touch on topics such as AI literacy for middle school students, identifying ethical issues in human-AI co-creation, and designing AI learning experiences for K-12 students. Other articles discuss specific AI applications, such as text-to-image generation and text-guided neural image inpainting.",
            "The abstract does not provide information on different generative AI prompting techniques or their application to solve business problems. Instead, it lists various sources related to AI, including research papers, blog posts, and news articles, covering topics such as human-centered AI, text-to-video generation, latent space, and AI education for children.",
            "The abstract does not provide information on the various generative AI prompting techniques. Instead, it lists references to related research and resources, including papers on human-centered AI, text-to-video generation, latent space, and text-guided neural image inpainting, among others. It also includes links to websites and datasets related to AI art and text-to-image generation. No specific information is provided on how these techniques work or their generalized applications.",
            "The abstract does not provide any information related to recent advancements in text-to-image generation systems or challenges that still need to be addressed in this field. Instead, it includes a list of references and a set of images used in a study.",
            "Recent advancements in text-to-video generation techniques have addressed issues of reliability, safety, and trustworthiness in human-centered AI. Researchers ensure that the generated images and videos in text-to-image and text-to-video generation techniques are aesthetically pleasing and appealing to human viewers. Potential applications of AI-generated art include creating personalized content, generating virtual environments, and enhancing storytelling. Ethical and social responsibility can be ensured by considering the impact of AI-generated art on society and promoting diversity and inclusion in the development process.",
            "The article does not provide an abstract or any information about generative AI prompting techniques. The provided references are not directly related to the topic.",
            "1. Rezwana and Maher identify key ethical issues in human-AI co-creation and suggest ways to address them in AI technology development.\n2. Williams et al. discuss lessons learned from project-based curricula for AI literacy in middle school students and how they can be applied to future AI education programs.\n3. Zhou et al. explore emerging works and future opportunities for designing AI learning experiences for K-12 students and propose a design framework to guide their development."
        ],
        "raw": [
            "16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020)",
            "16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020)",
            "16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020)",
            "16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017",
            "16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020)",
            "16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017",
            "aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) /\n\nBasic\n\n/\n\n/\n\nIntermediate\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\n/\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nOvercoming\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nOvercoming and Developing\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\n/\n\n/\n\n1\n\n0\n\n1\n\n/\n\n1\n\n1\n\n/\n\n0\n\n1\n\n1\n\n/\n\n/\n\n0\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n38\n\n/\n\n/\n\nNormal\n\nNormal\n\n/\n\n/\n\nLow\n\nLow\n\nNormal\n\nNormal\n\n/\n\n/\n\n/\n\n/\n\nNormal\n\nNormal\n\n/\n\n/\n\n/\n\n/\n\nNormal\n\nLow\n\nNormal\n\nNormal\n\n/\n\n/\n\nNormal\n\nNormal\n\nHigh\n\nNormal\n\n/\n\n/\n\nLow\n\nHigh\n\nLow\n\nHigh\n\nNormal\n\nNormal\n\n/\n\n/\n\nLow\n\nNormal\n\nNormal\n\nNormal\n\n/\n\n/\n\nNormal\n\nNormal\n\nLow\n\nNormal\n\n/\n\n/ 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020)",
            "aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 /\n\nBasic\n\n/\n\n/\n\nIntermediate\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\n/\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nOvercoming\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nOvercoming and Developing\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\n/\n\n/\n\n1\n\n0\n\n1\n\n/\n\n1\n\n1\n\n/\n\n0\n\n1\n\n1\n\n/\n\n/\n\n0\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n38\n\n/\n\n/\n\nNormal\n\nNormal\n\n/\n\n/\n\nLow\n\nLow\n\nNormal\n\nNormal\n\n/\n\n/\n\n/\n\n/\n\nNormal\n\nNormal\n\n/\n\n/\n\n/\n\n/\n\nNormal\n\nLow\n\nNormal\n\nNormal\n\n/\n\n/\n\nNormal\n\nNormal\n\nHigh\n\nNormal\n\n/\n\n/\n\nLow\n\nHigh\n\nLow\n\nHigh\n\nNormal\n\nNormal\n\n/\n\n/\n\nLow\n\nNormal\n\nNormal\n\nNormal\n\n/\n\n/\n\nNormal\n\nNormal\n\nLow\n\nNormal\n\n/\n\n/ [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017",
            "[55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per",
            "aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017",
            "aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 /\n\nBasic\n\n/\n\n/\n\nIntermediate\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\n/\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nOvercoming\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nOvercoming and Developing\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\n/\n\n/\n\n1\n\n0\n\n1\n\n/\n\n1\n\n1\n\n/\n\n0\n\n1\n\n1\n\n/\n\n/\n\n0\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n38\n\n/\n\n/\n\nNormal\n\nNormal\n\n/\n\n/\n\nLow\n\nLow\n\nNormal\n\nNormal\n\n/\n\n/\n\n/\n\n/\n\nNormal\n\nNormal\n\n/\n\n/\n\n/\n\n/\n\nNormal\n\nLow\n\nNormal\n\nNormal\n\n/\n\n/\n\nNormal\n\nNormal\n\nHigh\n\nNormal\n\n/\n\n/\n\nLow\n\nHigh\n\nLow\n\nHigh\n\nNormal\n\nNormal\n\n/\n\n/\n\nLow\n\nNormal\n\nNormal\n\nNormal\n\n/\n\n/\n\nNormal\n\nNormal\n\nLow\n\nNormal\n\n/\n\n/ [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017",
            "16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020)"
        ]
    },
    {
        "seed": "Find unique connections between various generative AI prompting techniques. Use this to create an abstract for a new research paper.",
        "summaries": [
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            "The chain of thought prompting technique is a cognitive strategy that involves guiding individuals through a series of interconnected thoughts or ideas in order to stimulate their thinking process and generate new insights or perspectives. This technique is often used in brainstorming sessions, problem-solving exercises, or creative thinking activities.\n\nThe chain of thought prompting technique typically starts with a specific question or prompt, which serves as the initial link in the chain. From there, individuals are encouraged to explore related ideas or concepts, building upon each previous link in the chain. This process helps to uncover connections, associations, and potential solutions that may not have been immediately apparent.\n\nBy following the chain of thought, individuals are able to delve deeper into a topic, consider different angles, and explore various possibilities. This technique can be particularly useful in breaking through mental blocks, encouraging divergent thinking, and fostering creativity.\n\nOverall, the chain of thought prompting technique is a valuable tool for stimulating and expanding one's thinking process, allowing for the generation of new ideas and insights.",
            "The chain of thought prompting technique is a reasoning process used to solve problems or answer questions. It involves breaking down the problem or question into smaller steps and logically connecting them to arrive at a solution. \n\nIn the provided examples, the chain of thought prompting technique is used to solve various problems. In the first example, the speed of a boat in still water is determined by considering the speed of the current and the time it takes for the boat to travel a certain distance. By setting up equations and solving for the unknown variable, the speed of the boat in still water is found to be 8 km/hr.\n\nIn the second example, the distance covered by a car in a given time is calculated by converting the speed from km/hr to meters/second and multiplying it by the time in seconds. The distance is found to be 378.89 meters.\n\nIn the third example, the location where peanut butter can be stored is determined by reasoning that food items are usually stored in places where they can stay fresh, such as a refrigerator or a pantry. The correct answer is determined to be a pantry.\n\nIn the fourth example, the location where the person's friend might be waiting is reasoned by considering the context of the squash court and eliminating options that do not fit. The correct answer is determined to be a park.\n\nIn the fifth example, the desired action of people who love a place they are going on vacation is reasoned by considering the options given and selecting the one that makes the most sense. The correct answer is determined to be staying there.\n\nOverall, the chain of thought prompting technique involves logical reasoning, problem-solving, and elimination of incorrect options to arrive at the correct answer. It can be applied to various types of problems and questions.",
            "The chain of thought prompting technique is a reasoning process used to solve problems or answer questions. It involves breaking down the problem or question into smaller steps and logically connecting them to arrive at a solution. \n\nIn the provided examples, the chain of thought prompting technique is used to solve various problems. In the first example, the speed of a boat in still water is determined by considering the speed of the current and the time it takes for the boat to travel a certain distance. By setting up equations and solving for the unknown variable, the speed of the boat in still water is found to be 8 km/hr.\n\nIn the second example, the distance covered by a car in a given time is calculated by converting the speed from km/hr to meters/second and multiplying it by the time in seconds. The distance is found to be 378.89 meters.\n\nIn the third example, the location where peanut butter can be stored is determined by reasoning that food items are usually stored in places where they can stay fresh, such as a refrigerator or a pantry. The correct answer is determined to be a pantry.\n\nIn the fourth example, the location where the person's friend might be waiting is reasoned by considering the context of the squash court and eliminating options that do not fit. The correct answer is determined to be a park.\n\nIn the fifth example, the desired action of people who love a place they are going on vacation is reasoned by considering the options given and selecting the one that makes the most sense. The correct answer is determined to be staying there.\n\nOverall, the chain of thought prompting technique involves logical reasoning, problem-solving, and elimination of incorrect options to arrive at the correct answer. It can be applied to various types of problems and questions.",
            "The zero-shot prompting technique is a method used in natural language processing (NLP) to generate instructions for a given task without any prior training on that specific task. It involves using pre-trained language models (LLMs) to propose instructions for various tasks.\n\nThe technique is evaluated using different metrics and LLM models. The results show the zero-shot test accuracy on 24 Instruction Induction tasks. Additionally, the technique is compared to in-context learning without instruction and in-context learning with instruction.\n\nTo improve the quality of the instruction candidates, an iterative Monte Carlo search is employed. This search process is performed at each round for tasks such as Antonyms, Cause Selection, Passivization, Second Letter, Sentiment, and Translation en-fr.\n\nThe technique has been published as a conference paper at ICLR 2023 and the results are presented in figures 24 to 34. These figures show the test accuracy, survival function, and histogram of test accuracy for different tasks and models.\n\nIn summary, the zero-shot prompting technique allows for generating instructions for various tasks without prior training. It utilizes pre-trained language models and iterative Monte Carlo search to improve the quality of the instructions. The technique has been evaluated and compared using different metrics and models, and the results are presented in the conference paper.",
            "The few-shot prompting technique is a method used in natural language processing (NLP) to generate instructions for various tasks without prior training. It involves using pre-trained language models (LLMs) to propose instructions. The technique has been evaluated using different metrics and LLM models, and the results show the zero-shot test accuracy on 24 Instruction Induction tasks.\n\nTo improve the quality of the instruction candidates, an iterative Monte Carlo search is employed. This search process is performed at each round for tasks such as Antonyms, Cause Selection, Passivization, Second Letter, Sentiment, and Translation en-fr. The iterative Monte Carlo search helps improve the quality of the instructions generated.\n\nThe application of the few-shot prompting technique involves utilizing pre-trained language models and selecting appropriate templates to propose instructions. The technique has been compared to in-context learning without instruction and in-context learning with instruction on 24 Instruction Induction tasks. The results, including test accuracy, survival function, and histogram of test accuracy, are presented in figures 24 to 34 of the conference paper.\n\nIn summary, the few-shot prompting technique allows for generating instructions for various tasks without prior training. It utilizes pre-trained language models and iterative Monte Carlo search to improve the quality of the instructions. The technique has been evaluated and compared using different metrics and models, and the results are presented in the conference paper."
        ],
        "raw": [
            "16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020) /\n\nBasic\n\n/\n\n/\n\nIntermediate\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\n/\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nOvercoming\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nOvercoming and Developing\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\nDeveloping\n\nIntermediate\n\nIntermediate\n\n/\n\n/\n\n1\n\n0\n\n1\n\n/\n\n1\n\n1\n\n/\n\n0\n\n1\n\n1\n\n/\n\n/\n\n0\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n38\n\n/\n\n/\n\nNormal\n\nNormal\n\n/\n\n/\n\nLow\n\nLow\n\nNormal\n\nNormal\n\n/\n\n/\n\n/\n\n/\n\nNormal\n\nNormal\n\n/\n\n/\n\n/\n\n/\n\nNormal\n\nLow\n\nNormal\n\nNormal\n\n/\n\n/\n\nNormal\n\nNormal\n\nHigh\n\nNormal\n\n/\n\n/\n\nLow\n\nHigh\n\nLow\n\nHigh\n\nNormal\n\nNormal\n\n/\n\n/\n\nLow\n\nNormal\n\nNormal\n\nNormal\n\n/\n\n/\n\nNormal\n\nNormal\n\nLow\n\nNormal\n\n/\n\n/ aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 16. Kahn, K.M., Megasari, R., Piantari, E., Junaeti, E.: Ai programming by children\n\nusing snap! block programming in a developing country (2018)\n\n17. Milmo, D.: Chatgpt reaches 100 million users two months after launch. The\n\nGuardian (2023)\n\n18. Papert, S., Harel, I.: Situating constructionism. constructionism 36(2), 1\u201311 (1991) 19. Pinkard, N., Erete, S., Martin, C.K., McKinney de Royston, M.: Digital youth divas: Exploring narrative-driven curriculum to spark middle school girls\u2019 interest in computational activities. Journal of the Learning Sciences 26(3), 477\u2013516 (2017) 20. Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., Sutskever, I.: Zero-shot text-to-image generation. In: International Conference on Machine Learning. pp. 8821\u20138831. PMLR (2021)\n\n21. Rezwana, J., Maher, M.L.: Identifying ethical issues in ai partners in human-ai\n\nco-creation. arXiv preprint arXiv:2204.07644 (2022)\n\n22. Rombach, R., Blattmann, A., Lorenz, D., Esser, P., Ommer, B.: High-resolution image synthesis with latent di\ufb00usion models. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 10684\u201310695 (2022) 23. Taylor, M.: Self-identity and the arts education of disabled young people. Disability\n\n& Society 20(7), 763\u2013778 (2005)\n\n24. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D.: Envisioning ai for k- 12: What should every child know about ai? In: Proceedings of the AAAI conference on arti\ufb01cial intelligence. vol. 33, pp. 9795\u20139799 (2019)\n\n25. Umaschi Bers, M.: Identity construction environments: Developing personal and moral values through the design of a virtual city. The Journal of the Learning Sciences 10(4), 365\u2013415 (2001)\n\n26. Williams, R., Ali, S., Devasia, N., DiPaola, D., Hong, J., Kaputsos, S.P., Jordan, B., Breazeal, C.: Ai+ ethics curricula for middle school youth: Lessons learned from three project-based curricula. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201359 (2022)\n\n27. Zhang, H., Lee, I., Ali, S., DiPaola, D., Cheng, Y., Breazeal, C.: Integrating ethics and career futures with technical learning to promote ai literacy for middle school students: An exploratory study. International Journal of Arti\ufb01cial Intelligence in Education pp. 1\u201335 (2022)\n\n28. Zhang, Q.: Asian americans beyond the model minority stereotype: The nerdy and the left out. Journal of international and intercultural communication 3(1), 20\u201337 (2010)\n\n29. Zhou, X., Van Brummelen, J., Lin, P.: Designing ai learning experiences for k- 12: emerging works, future opportunities and a design framework. arXiv preprint arXiv:2009.10228 (2020)",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5",
            "Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. CA 62.8 36.4 33.4 57.1 38.0\n\nPE 53.0 23.8 25.6 54.6 34.3\n\nFULL 54.4 27.4 28.0 52.6 37.1\n\nZS 67.0 30.9 18.0 66.2 36.9\n\nCA 70.0 41.8 38.6 57.5 40.0\n\nPE 49.4 27.4 26.8 51.8 36.0\n\nFULL 54.2 30.1 27.4 52.6 38.0\n\nZS 69.8 33.3 21.6 69.6 36.6\n\nCA 69.4 44.5 41.4 60.7 40.3\n\nPE 51.4 26.9 25.2 55.0 34.0\n\nFULL 57.4 33.2 29.4 54.6 35.6\n\nZS 69.0 38.6 22.4 69.6 39.0\n\nCA 71.6 47.8 43.2 62.2 41.0\n\nPE 51.4 35.1 25.8 52.6 35.2\n\nFULL 53.0 36.2 29.4 53.4 35.9\n\nTable 5: Accuracy (%) on T5\n\nModel\n\nCOPA CSQA OBQA PIQA SIQA\n\nT5-Small (80M)\n\nT5-Base (250M)\n\nT5-Large (780M)\n\nZS 55.2 16.6 14.2 56.6 36.2\n\nCA 51.2 22.8 28.8 50.5 36.1\n\nPE 51.2 21.1 23.8 51.2 35.0\n\nFULL 52.2 21.0 25.8 50.8 34.4\n\nZS 59.6 26.1 15.8 61.0 36.2\n\nCA 59.4 30.0 30.8 57.7 37.6\n\nPE 51.0 20.6 27.8 51.7 37.0\n\nFULL 51.8 22.5 27.2 53.0 33.5\n\nZS 65.2 39.2 19.0 66.6 38.7\n\nCA 56.6 35.4 30.4 64.4 38.1\n\nPE 53.2 33.1 24.8 52.8 37.0\n\nFULL 53.8 35.7 26.4 51.7 34.1\n\nD CODE\n\nOur Prompt-engineering-and-calibration-0AE0/README.md\n\navailable\n\ncode\n\nat\n\nis\n\nhttps://anonymous.4open.science/r/\n\n6 Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43",
            "Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D."
        ]
    },
    {
        "seed": "Explain the few-shot prompting technique.",
        "summaries": [
            "The few-shot prompting technique is a method used to improve the performance of language models in tasks that require understanding and generating instructions. It involves using a small number of example instructions, known as prompts, to guide the model's behavior.\n\nThe technique works by providing the model with a set of prompts that demonstrate the desired behavior or output. These prompts can be specific instructions or examples of the desired output. The model is then fine-tuned using these prompts, allowing it to learn how to generate accurate and relevant instructions.\n\nThe application of the few-shot prompting technique involves several steps. First, a set of example instructions or outputs is selected to serve as prompts. These prompts should cover a range of desired behaviors or outputs. Next, the model is fine-tuned using these prompts, adjusting its parameters to improve its performance on the given task. Finally, the fine-tuned model can be used to generate instructions or outputs for new inputs.\n\nThe effectiveness of the few-shot prompting technique can be evaluated by measuring the model's accuracy on a set of test tasks. This can be done by comparing the model's performance with different templates used to propose instructions. Additionally, zero-shot and in-context learning experiments can be conducted to assess the model's ability to generate instructions without any prior examples or with additional context.\n\nIn summary, the few-shot prompting technique is a method that uses a small number of example instructions to guide the behavior of language models. It involves fine-tuning the model using these prompts to improve its performance on specific tasks. The technique can be applied by selecting appropriate prompts, fine-tuning the model, and evaluating its accuracy on test tasks.",
            "The few-shot prompting technique is a method used to improve the performance of language models in tasks that require understanding and generating instructions. It involves using a small number of example instructions, known as prompts, to guide the model's behavior.\n\nThe technique works by providing the model with a set of prompts that demonstrate the desired behavior or output. These prompts can be specific instructions or examples of the desired output. The model is then fine-tuned using these prompts, allowing it to learn how to generate accurate and relevant instructions.\n\nThe application of the few-shot prompting technique involves several steps. First, a set of example instructions or outputs is selected to serve as prompts. These prompts should cover a range of possible inputs and desired outputs. Next, the model is fine-tuned using these prompts, adjusting its parameters to improve its performance on the given task. Finally, the fine-tuned model can be used to generate instructions or outputs for new inputs.\n\nThe effectiveness of the few-shot prompting technique can be evaluated by measuring the model's accuracy on a set of test tasks. This can be done by comparing the model's performance with different templates used to propose instructions. Additionally, zero-shot and in-context learning experiments can be conducted to assess the model's ability to generate instructions without any prior training or with additional context.\n\nOverall, the few-shot prompting technique is a valuable approach for improving the performance of language models in tasks that require instruction generation. By providing the model with a small number of example prompts, it can learn to generate accurate and relevant instructions, enhancing its overall performance.",
            "The few-shot prompting technique is a method used to improve the performance of language models in tasks that require understanding and generating instructions. It involves using a small number of example instructions, known as prompts, to guide the model's behavior.\n\nThe technique works by providing the model with a set of prompts that demonstrate the desired behavior or output. These prompts can be specific instructions or examples of the desired output. The model is then fine-tuned using these prompts, allowing it to learn how to generate accurate and relevant instructions.\n\nThe application of the few-shot prompting technique involves several steps. First, a set of example instructions or outputs is selected to serve as prompts. These prompts should cover a range of desired behaviors or outputs. Next, the model is fine-tuned using these prompts, adjusting its parameters to improve its performance on the given task. Finally, the fine-tuned model can be used to generate instructions or outputs for new inputs.\n\nThe effectiveness of the few-shot prompting technique can be evaluated by measuring the model's accuracy on a set of test tasks. This can be done by comparing the model's performance with different templates used to propose instructions. Additionally, zero-shot and in-context learning experiments can be conducted to assess the model's ability to generate instructions without any prior examples or with additional context.\n\nOverall, the few-shot prompting technique is a valuable approach for improving the performance of language models in tasks that require instruction generation. By providing the model with a small number of example prompts, it can learn to generate accurate and relevant instructions, enhancing its overall performance.",
            "The few-shot prompting technique is a method used to improve the performance of language models in tasks that require understanding and generating instructions. It involves using a small number of example instructions, known as prompts, to guide the model's behavior.\n\nThe technique works by providing the model with a set of prompts that demonstrate the desired behavior or output. These prompts can be specific instructions or examples of the desired output. The model is then fine-tuned using these prompts, allowing it to learn how to generate accurate and relevant instructions.\n\nThe application of the few-shot prompting technique involves several steps. First, a set of example instructions or outputs is selected to serve as prompts. These prompts should cover a range of desired behaviors or outputs. Next, the model is fine-tuned using these prompts, adjusting its parameters to improve its performance on the given task. Finally, the fine-tuned model can be used to generate instructions or outputs for new inputs.\n\nThe effectiveness of the few-shot prompting technique can be evaluated by measuring the model's accuracy on a set of test tasks. This can be done by comparing the model's performance with different templates used to propose instructions. Additionally, zero-shot and in-context learning experiments can be conducted to assess the model's ability to generate instructions without any prior examples or with additional context.\n\nIn summary, the few-shot prompting technique is a method that uses a small number of example instructions to guide the behavior of language models. It involves fine-tuning the model using these prompts to improve its performance on specific tasks. The technique can be applied by selecting appropriate prompts, fine-tuning the model, and evaluating its accuracy on test tasks."
        ],
        "raw": [
            "Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per",
            "Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per",
            "Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per",
            "Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 Figure 22: Few-shot test accuracy on 6 Instruction Induction tasks. We compare the performance of different templates used to propose instruction. Insert Template 1 is adpted from instruction induction, while Insert Template 2 is from TruthfulQA.\n\n38\n\nPublished as a conference paper at ICLR 2023\n\nFigure 24: Zero-shot test accuracy on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 25: In-Context learning without instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\nFigure 26: Test accuracy of in-Context learning with instruction on 24 Instruction Induction tasks using two different metrics and two different LLM models.\n\n39\n\nPublished as a conference paper at ICLR 2023\n\nFigure 27: Survival function and the histogram of test accuracy on a simple task (i.e. Pluralization)\n\nFigure 28: Survival function and the histogram of test accuracy on a challenging task (i.e. Start With)\n\n40\n\nPublished as a conference paper at ICLR 2023\n\nFigure 29: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Antonyms.\n\nFigure 30: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Cause Selection.\n\n41\n\nPublished as a conference paper at ICLR 2023\n\nFigure 31: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Passivization.\n\nFigure 32: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Second Letter.\n\n42\n\nPublished as a conference paper at ICLR 2023\n\nFigure 33: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Sentiment.\n\nFigure 34: Iterative Monte Carlo search improves the quality of the instruction candidates at each round. Task: Translation en-fr.\n\n43 [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per"
        ]
    },
    {
        "seed": "Explain the tree-of-thought prompting technique.",
        "summaries": [
            "The tree-of-thought prompting technique is a method used to guide reasoning and problem-solving processes. It involves breaking down a complex problem into smaller, more manageable steps, represented as a tree structure. Each step in the tree represents a specific line of reasoning or thought process.\n\nIn the given examples, the tree-of-thought prompting technique is used to solve various problems. For instance, in the first example, the problem is to find the speed of a boat in still water. The tree of thought starts with assuming the speed of the boat in still water as x km/hr. It then considers the current of the stream (4 km/hr) and calculates the time taken to travel downcurrent and against the current. By adding these two times, the total time spent traveling is found to be 2 hours. Solving for x, the speed of the boat in still water is determined to be 8 km/hr.\n\nIn the second example, the problem is to find the distance covered by a car in 14 seconds. The tree of thought involves converting the given speed of the car (96 km/hr) to meters per second and then multiplying it by the time (14 seconds) to find the distance. The final answer is determined to be 378.89 meters.\n\nIn the third example, the problem is to determine where peanut butter can be stored. The tree of thought considers that peanut butter is a food item and is usually stored in a place where it can stay fresh, such as a refrigerator or a pantry. The final answer is determined to be a pantry.\n\nIn the fourth example, the problem is to figure out where the person's friend might be waiting. The tree of thought considers that the person is waiting at a squash court, which suggests they are likely at a sports facility or gym. The only option that seems plausible as being at the other end of a public place is a park. Therefore, the final answer is determined to be a park.\n\nIn the fifth example, the problem is to identify what people want to do when they love a place they are going on vacation to. The tree of thought considers the given options and concludes that the only option that makes sense is staying there. Therefore, the final answer is determined to be staying there.\n\nOverall, the tree-of-thought prompting technique helps break down complex problems into smaller steps, guiding the reasoning process and facilitating problem-solving. It allows for a systematic approach to analyzing and solving problems by considering different lines of thought and reasoning.",
            "The tree-of-thought prompting technique is a method used to guide reasoning and problem-solving processes by breaking down complex problems into smaller, more manageable steps represented as a tree structure, with each step representing a specific line of reasoning or thought process. This technique is used to solve various problems by considering different lines of thought and reasoning.\n\nIn the given examples, the tree-of-thought prompting technique is applied to solve different problems. Each problem is broken down into a series of logical steps, represented as a tree structure. The reasoning process is explained step by step, considering different factors and options.\n\nFor example, in the problem of finding the speed of a boat in still water, the reasoning process involves assuming the speed of the boat in still water as x km/hr and considering the current of the stream. The boat's travel time downcurrent and against the current is calculated, and the total time spent is equated to 2 hours. By solving the equations, the speed of the boat in still water is determined to be 8 km/hr.\n\nSimilarly, in the problem of calculating the distance covered by a car in a given time, the reasoning process involves converting the speed from km/hr to meters per second and calculating the distance using the formula distance = speed * time. The distance is determined to be 378.89 meters.\n\nThe tree-of-thought prompting technique can be executed by breaking down a problem into smaller steps and considering different factors and options at each step. Each step represents a specific line of reasoning or thought process. By systematically analyzing and solving each step, the overall problem can be solved.\n\nIn summary, the tree-of-thought prompting technique is a problem-solving approach that breaks down complex problems into smaller steps represented as a tree structure. It allows for systematic reasoning and consideration of different factors and options. By applying this technique, problems can be solved by analyzing and solving each step of the tree structure.",
            "The tree-of-thought prompting technique is a problem-solving approach that breaks down complex problems into smaller steps represented as a tree structure. It allows for systematic reasoning and consideration of different factors and options. By applying this technique, problems can be solved by analyzing and solving each step of the tree structure.\n\nIn the given examples, the tree-of-thought prompting technique is used to solve various problems. Each problem is broken down into smaller steps, and the reasoning process is explained step by step. The technique involves identifying relevant information, making logical deductions, and considering different options to arrive at the correct answer.\n\nFor example, in the first problem about the speed of a boat in still water, the technique is applied by assuming the speed of the boat as x km/hr and considering the current of the stream as 4 km/hr. The problem is then broken down into two steps: the boat traveling downcurrent and the boat traveling against the current. By solving the equations derived from these steps, the speed of the boat in still water is determined to be 8 km/hr.\n\nIn the second problem about the distance covered by a car in a given time, the technique is applied by converting the given speed of the car from km/hr to meters per second and calculating the distance covered in 14 seconds. The problem is broken down into several steps involving unit conversions and calculations. The final answer is determined to be 378 meters.\n\nIn the other examples, the technique is applied in a similar manner to solve problems related to storing peanut butter, waiting at a squash court, and people's desires when they love a vacation destination.\n\nOverall, the tree-of-thought prompting technique is a systematic approach that breaks down complex problems into smaller steps, allowing for logical reasoning and consideration of different factors and options. It can be applied by identifying relevant information, making logical deductions, and solving each step of the problem tree to arrive at the correct answer.",
            "The tree-of-thought prompting technique is a method used to guide reasoning and problem-solving processes. It involves breaking down a complex problem into smaller, more manageable steps, represented as a tree structure. Each step or node in the tree represents a specific thought or action that needs to be taken to solve the problem.\n\nIn the given examples, the reasoning process is demonstrated through a series of steps that lead to the final answer. For example, in the first question about the speed of a boat in still water, the problem is broken down into calculating the time taken to travel downcurrent and against the current. By adding these two times and solving for the boat speed, the answer is determined to be 8 km/hr.\n\nTo apply the tree-of-thought prompting technique, one needs to analyze the problem and identify the key steps or thoughts required to reach a solution. These steps can then be organized in a hierarchical tree structure, with each step branching out into further sub-steps if necessary. By following this structured approach, individuals can systematically work through the problem and arrive at a solution.\n\nThe tree-of-thought prompting technique can be applied to various problem-solving scenarios, including mathematical calculations, logical reasoning, and decision-making processes. It helps individuals break down complex problems into simpler components, making it easier to understand and solve them. By providing a clear framework for thinking and problem-solving, this technique enhances cognitive processes and improves overall problem-solving skills."
        ],
        "raw": [
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Dragomir R Radev, Richard Socher, and Caiming Xiong. 2021. Grappa: Grammar-augmented pre-training for table semantic parsing. In ICLR.\n\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingn- ing Yao, Shanelle Roman, et al. 2018. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. In Proceedings of the 2018 Conference on Empiri- cal Methods in Natural Language Processing, pages 3911\u20133921.\n\nHongzhi Zhang, Yingyao Wang, Sirui Wang, Xuezhi Cao, Fuzheng Zhang, and Zhongyuan Wang. 2020. Table fact veri\ufb01cation with structure-aware trans- former. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1624\u20131629.\n\nYuchen Zhang, Panupong Pasupat, and Percy Liang. 2017. Macro grammars and holistic triggering for ef- \ufb01cient semantic parsing. In Proceedings of the 2017 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1214\u20131223.\n\nVictor Zhong, Caiming Xiong, and Richard Socher. 2017. Seq2sql: Generating structured queries from natural language using reinforcement learning. arXiv preprint arXiv:1709.00103.\n\nWanjun Zhong, Duyu Tang, Zhangyin Feng, Nan Duan, Ming Zhou, Ming Gong, Linjun Shou, Daxin Jiang, Jiahai Wang, and Jian Yin. 2020. Logical- factchecker: Leveraging logical operations for fact checking with graph module network. In Proceed- ings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6053\u20136065.",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Dragomir R Radev, Richard Socher, and Caiming Xiong. 2021. Grappa: Grammar-augmented pre-training for table semantic parsing. In ICLR.\n\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingn- ing Yao, Shanelle Roman, et al. 2018. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. In Proceedings of the 2018 Conference on Empiri- cal Methods in Natural Language Processing, pages 3911\u20133921.\n\nHongzhi Zhang, Yingyao Wang, Sirui Wang, Xuezhi Cao, Fuzheng Zhang, and Zhongyuan Wang. 2020. Table fact veri\ufb01cation with structure-aware trans- former. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1624\u20131629.\n\nYuchen Zhang, Panupong Pasupat, and Percy Liang. 2017. Macro grammars and holistic triggering for ef- \ufb01cient semantic parsing. In Proceedings of the 2017 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1214\u20131223.\n\nVictor Zhong, Caiming Xiong, and Richard Socher. 2017. Seq2sql: Generating structured queries from natural language using reinforcement learning. arXiv preprint arXiv:1709.00103.\n\nWanjun Zhong, Duyu Tang, Zhangyin Feng, Nan Duan, Ming Zhou, Ming Gong, Linjun Shou, Daxin Jiang, Jiahai Wang, and Jian Yin. 2020. Logical- factchecker: Leveraging logical operations for fact checking with graph module network. In Proceed- ings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6053\u20136065.",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Dragomir R Radev, Richard Socher, and Caiming Xiong. 2021. Grappa: Grammar-augmented pre-training for table semantic parsing. In ICLR.\n\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingn- ing Yao, Shanelle Roman, et al. 2018. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. In Proceedings of the 2018 Conference on Empiri- cal Methods in Natural Language Processing, pages 3911\u20133921.\n\nHongzhi Zhang, Yingyao Wang, Sirui Wang, Xuezhi Cao, Fuzheng Zhang, and Zhongyuan Wang. 2020. Table fact veri\ufb01cation with structure-aware trans- former. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1624\u20131629.\n\nYuchen Zhang, Panupong Pasupat, and Percy Liang. 2017. Macro grammars and holistic triggering for ef- \ufb01cient semantic parsing. In Proceedings of the 2017 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1214\u20131223.\n\nVictor Zhong, Caiming Xiong, and Richard Socher. 2017. Seq2sql: Generating structured queries from natural language using reinforcement learning. arXiv preprint arXiv:1709.00103.\n\nWanjun Zhong, Duyu Tang, Zhangyin Feng, Nan Duan, Ming Zhou, Ming Gong, Linjun Shou, Daxin Jiang, Jiahai Wang, and Jian Yin. 2020. Logical- factchecker: Leveraging logical operations for fact checking with graph module network. In Proceed- ings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6053\u20136065.",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Dragomir R Radev, Richard Socher, and Caiming Xiong. 2021. Grappa: Grammar-augmented pre-training for table semantic parsing. In ICLR.\n\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingn- ing Yao, Shanelle Roman, et al. 2018. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. In Proceedings of the 2018 Conference on Empiri- cal Methods in Natural Language Processing, pages 3911\u20133921.\n\nHongzhi Zhang, Yingyao Wang, Sirui Wang, Xuezhi Cao, Fuzheng Zhang, and Zhongyuan Wang. 2020. Table fact veri\ufb01cation with structure-aware trans- former. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1624\u20131629.\n\nYuchen Zhang, Panupong Pasupat, and Percy Liang. 2017. Macro grammars and holistic triggering for ef- \ufb01cient semantic parsing. In Proceedings of the 2017 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1214\u20131223.\n\nVictor Zhong, Caiming Xiong, and Richard Socher. 2017. Seq2sql: Generating structured queries from natural language using reinforcement learning. arXiv preprint arXiv:1709.00103.\n\nWanjun Zhong, Duyu Tang, Zhangyin Feng, Nan Duan, Ming Zhou, Ming Gong, Linjun Shou, Daxin Jiang, Jiahai Wang, and Jian Yin. 2020. Logical- factchecker: Leveraging logical operations for fact checking with graph module network. In Proceed- ings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6053\u20136065."
        ]
    },
    {
        "seed": "Explain the tree-of-thought prompting technique and how it can be used with chain of thought.",
        "summaries": [
            "The tree-of-thought prompting technique is a method used to guide the thought process and reasoning behind answering a question or solving a problem. It involves breaking down the problem into smaller components and considering different possibilities or options at each step. This technique can be used in conjunction with the chain of thought approach, which involves sequentially exploring different lines of reasoning to arrive at a solution.\n\nIn the provided examples, the tree-of-thought prompting technique is used to analyze and solve the given questions. The reasoning process involves considering relevant information and making logical deductions to arrive at the correct answer.\n\nFor example, in the first question about the speed of a boat in still water, the tree-of-thought prompting technique is used to calculate the boat's speed. The process involves assuming the boat's speed in still water as x km/hr and considering the current of the stream as 4 km/hr. By calculating the time taken to travel downcurrent and against the current, and adding them together, the total time of 2 hours is obtained. Solving for x, the boat's speed in still water is determined to be 8 km/hr.\n\nSimilarly, in the second question about the distance covered by a car in a given time, the tree-of-thought prompting technique is used to convert the given speed from km/hr to meters per second and calculate the distance covered in 14 seconds. By converting the speed and using the formula distance = speed * time, the distance of 378.89 meters is obtained.\n\nThe tree-of-thought prompting technique can be executed by systematically analyzing the given information, breaking down the problem into smaller components, and considering different possibilities or options at each step. It involves logical reasoning and calculations to arrive at the correct answer.\n\nOverall, the tree-of-thought prompting technique is a valuable approach for problem-solving and reasoning, and when used in conjunction with the chain of thought, it can help guide the thought process and lead to accurate solutions.",
            "The tree-of-thought prompting technique is a method used to guide the thought process and reasoning behind answering a question or solving a problem. It involves breaking down the problem into smaller components and considering different possibilities or options at each step. This technique can be used in conjunction with the chain of thought approach, which involves sequentially exploring different lines of reasoning to arrive at a solution.\n\nIn the given examples, the tree-of-thought prompting technique is applied to solve the questions. The reasoning process involves considering different factors and options to arrive at the correct answer. For example, in the first question about the speed of a boat in still water, the researcher assumes the speed of the boat as x km/hr and considers the current of the stream as 4 km/hr. By calculating the time taken to travel downcurrent and against the current, and adding them up to equal 2 hours, the speed of the boat in still water is determined to be 8 km/hr.\n\nSimilarly, in the second question about the distance covered by a car in 14 seconds, the researcher converts the given speed of the car from km/hr to meters per second and calculates the distance covered using the formula distance = speed * time. The distance is found to be 378.89 meters.\n\nThe tree-of-thought prompting technique can be executed by systematically analyzing the problem, considering relevant factors, and exploring different possibilities or options at each step. It helps in organizing thoughts and guiding the reasoning process to arrive at a solution. By breaking down the problem into smaller components and considering different lines of thought, it allows for a comprehensive and systematic approach to problem-solving.\n\nOverall, the tree-of-thought prompting technique is a valuable tool for problem-solving and reasoning. It helps in structuring the thought process and considering different possibilities, leading to more accurate and informed answers."
        ],
        "raw": [
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. ai/blog/against-llm-maximalism. Accessed: 21/05/2023. [32] replit. (2023) Replit. https://replit.com/. Accessed: 21/05/2023. [33] Y. Nakajima,\n\nhttps://github.com/features/\n\n\u201cCodespaces,\u201d\n\ncodespaces, 2023, accessed: 21/05/2023.\n\n[34] replit. (2023) Jupyter notebook. https://jupyter.org/. Accessed:\n\n21/05/2023.\n\n[35] microsoft. (2023) Microsoft ai builder. https://powerautomate.\n\nmicrosoft.com/zh-cn/ai-builder/. Accessed: 21/05/2023.\n\n[36] zapier. (2023) Zapier. https://zapier.com/. Accessed: 21/05/2023. superbio.ai. https://www.superbio.ai/. Ac- [37] superbio.\n\n(2023)\n\ncessed: 21/05/2023.\n\n[38] github.\n\n(2023) Github copilot. https://github.com/features/\n\ncopilot. Accessed: 21/05/2023.\n\n[39] replit.\n\n(2023)\n\nreplit\n\nghostwriter.\n\nhttps://replit.com/site/\n\nghostwriter. Accessed: 21/05/2023.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n\n[40] K. Czarnecki and U. W. Eisenecker, Generative Programming: Meth- ods, Tools, and Applications. USA: ACM Press/Addison-Wesley Publishing Co., 2000.\n\n8",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. ai/blog/against-llm-maximalism. Accessed: 21/05/2023. [32] replit. (2023) Replit. https://replit.com/. Accessed: 21/05/2023. [33] Y. Nakajima,\n\nhttps://github.com/features/\n\n\u201cCodespaces,\u201d\n\ncodespaces, 2023, accessed: 21/05/2023.\n\n[34] replit. (2023) Jupyter notebook. https://jupyter.org/. Accessed:\n\n21/05/2023.\n\n[35] microsoft. (2023) Microsoft ai builder. https://powerautomate.\n\nmicrosoft.com/zh-cn/ai-builder/. Accessed: 21/05/2023.\n\n[36] zapier. (2023) Zapier. https://zapier.com/. Accessed: 21/05/2023. superbio.ai. https://www.superbio.ai/. Ac- [37] superbio.\n\n(2023)\n\ncessed: 21/05/2023.\n\n[38] github.\n\n(2023) Github copilot. https://github.com/features/\n\ncopilot. Accessed: 21/05/2023.\n\n[39] replit.\n\n(2023)\n\nreplit\n\nghostwriter.\n\nhttps://replit.com/site/\n\nghostwriter. Accessed: 21/05/2023.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n\n[40] K. Czarnecki and U. W. Eisenecker, Generative Programming: Meth- ods, Tools, and Applications. USA: ACM Press/Addison-Wesley Publishing Co., 2000.\n\n8"
        ]
    },
    {
        "seed": "Explain the Chain of THought prompting technique.",
        "summaries": [
            "The Chain of Thought prompting technique is a method used to solve reasoning-based questions by breaking down the problem into smaller steps and logically connecting them. It involves analyzing the given information, identifying relevant concepts, and applying logical reasoning to arrive at the correct answer.\n\nIn the first example provided, the question asks for the speed of a boat in still water. The key steps in the chain of thought are as follows:\n1. Assume the speed of the boat in still water is x km/hr.\n2. Calculate the time taken to travel downcurrent and against the current using the given distance and the speed of the stream.\n3. Add the two times together to find the total time spent traveling.\n4. Set up an equation using the total time and solve for x to find the speed of the boat in still water.\n5. The final answer is the value of x, which is 8 km/hr.\n\nIn the second example, the question asks for the distance covered by a car in a given time. The key steps in the chain of thought are as follows:\n1. Convert the speed of the car from km/hr to meters/second.\n2. Multiply the speed by the time to find the distance covered.\n3. The final answer is the distance covered, which is 378.89 meters.\n\nIn the third example, the question asks where peanut butter can be stored. The key steps in the chain of thought are as follows:\n1. Identify that peanut butter is a food item.\n2. Determine that food items are usually stored in places where they can stay fresh, such as a refrigerator or a pantry.\n3. Choose the option that aligns with this reasoning, which is a pantry.\n\nIn the fourth example, the question asks where the person's friend might be waiting. The key steps in the chain of thought are as follows:\n1. Consider that the person is waiting at a squash court, indicating they are likely at a sports facility or gym.\n2. Evaluate the options and choose the one that could be at the other end of a public place, which is a park.\n\nIn the fifth example, the question asks what people want to do when they love a place they are going on vacation to. The key steps in the chain of thought are as follows:\n1. Recognize that people want to do something when they love a place they are visiting.\n2. Evaluate the options and choose the one that makes sense in this context, which is staying there.\n\nOverall, the Chain of Thought prompting technique involves breaking down a problem into smaller steps, applying logical reasoning, and connecting the steps to arrive at the correct answer. It can be applied to various types of reasoning-based questions to facilitate problem-solving.",
            "The tree-of-thought prompting technique is a method used to solve reasoning-based questions by breaking down the problem into smaller steps and logically connecting them. It involves analyzing the given information, identifying relevant concepts, and applying logical reasoning to arrive at the correct answer.\n\nIn the provided examples, the technique is applied to solve various reasoning-based questions. For each question, the reasoning process is outlined step by step, showing how the given information is analyzed and logically connected to arrive at the final answer.\n\nIn the first example, the question asks for the speed of a boat in still water. The given information includes the speed of the stream and the time it takes for the boat to travel a certain distance. By assuming the speed of the boat in still water as x km/hr, the time taken to travel downcurrent and against the current can be calculated. By adding these two times and solving for x, the speed of the boat in still water is determined to be 8 km/hr.\n\nIn the second example, the question asks for the distance covered by a car in a certain time. The given information includes the speed of the car and the time. By converting the units of speed and time to meters and seconds, the distance covered in 14 seconds can be calculated. The final answer is determined to be 378 meters.\n\nIn the third example, the question asks where peanut butter can be stored. By analyzing the nature of peanut butter as a food item and considering where food items are usually stored, the answer is determined to be a pantry.\n\nIn the fourth example, the question asks where the person is waiting for their friend. By considering the context of waiting at a squash court and the options provided, the answer is determined to be a park.\n\nIn the fifth example, the question asks what people want to do when they love a place they are going on vacation to. By considering the options provided and the concept of loving a place, the answer is determined to be staying there.\n\nOverall, the tree-of-thought prompting technique involves breaking down reasoning-based questions into smaller steps and logically connecting them to arrive at the correct answer. It can be applied to various types of questions and requires analyzing the given information, identifying relevant concepts, and applying logical reasoning."
        ],
        "raw": [
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. ai/blog/against-llm-maximalism. Accessed: 21/05/2023. [32] replit. (2023) Replit. https://replit.com/. Accessed: 21/05/2023. [33] Y. Nakajima,\n\nhttps://github.com/features/\n\n\u201cCodespaces,\u201d\n\ncodespaces, 2023, accessed: 21/05/2023.\n\n[34] replit. (2023) Jupyter notebook. https://jupyter.org/. Accessed:\n\n21/05/2023.\n\n[35] microsoft. (2023) Microsoft ai builder. https://powerautomate.\n\nmicrosoft.com/zh-cn/ai-builder/. Accessed: 21/05/2023.\n\n[36] zapier. (2023) Zapier. https://zapier.com/. Accessed: 21/05/2023. superbio.ai. https://www.superbio.ai/. Ac- [37] superbio.\n\n(2023)\n\ncessed: 21/05/2023.\n\n[38] github.\n\n(2023) Github copilot. https://github.com/features/\n\ncopilot. Accessed: 21/05/2023.\n\n[39] replit.\n\n(2023)\n\nreplit\n\nghostwriter.\n\nhttps://replit.com/site/\n\nghostwriter. Accessed: 21/05/2023.\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015\n\n[40] K. Czarnecki and U. W. Eisenecker, Generative Programming: Meth- ods, Tools, and Applications. USA: ACM Press/Addison-Wesley Publishing Co., 2000.\n\n8",
            "Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Zhuosheng Zhang, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. Multimodal\n\nchain-of-thought reasoning in language models. arXiv preprint arXiv:2302.00923, 2023b.\n\n3\n\nPublished as a Tiny Paper at ICLR 2023\n\nDenny Zhou, Nathanael Sch\u00a8arli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schu- urmans, Olivier Bousquet, Quoc Le, and Ed Chi. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625, 2022a.\n\nYongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv:2211.01910, 2022b.\n\nA APPENDIX\n\nTable 1: Batch size of four different datasets\n\nBatch Size\n\nMultiArith GSM8K StrategyQA 64\n\n32\n\n60\n\nLetter 81\n\nFigure 1: Left: accuracy for MultiArith dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for MultiArith dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 2: Left: accuracy for GSM8K dataset under Correct-CoT and Wrong-CoT. Right: accuracy for GSM8K dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\n4\n\nPublished as a Tiny Paper at ICLR 2023\n\nFigure 3: Left: accuracy for StrategyQA dataset under Correct-CoT and Wrong-CoT. Right: accu- racy for StrategyQA dataset under Deep-CoT and Shallow-CoT with \u03be = 3.\n\nFigure 4: Left: accuracy for Letter dataset under Correct-CoT and Wrong-CoT. Right: accuracy for Letter dataset under Deep-CoT and Shallow-CoT with \u03be = 4.\n\n5 Q: The current of a stream runs at the rate of 4 kmph. A boat goes 6 km and back to the starting point in 2 hours, then \ufb01nd the speed of the boat in still water? Options: A:6 B:7 C:8 D:5 E:3 A: Reasoning process: First, let\u2019s assume that the speed of the boat in still water is x km/hr. Since the current of the stream is 4 km/hr, the boat travels 6 km downcurrent in 6 km / (4 km/hr + x km/hr) hours. Similarly, the boat travels 6 km against the current in 6 km / (x km/hr - 4 km/hr) hours. Adding these two times, we \ufb01nd that the total time the boat spends traveling downcurrent and against the current is 2 hours. Solving for x, we \ufb01nd that the boat speed in still water is 8 km/hr. Final answer: C.\n\nQ: A car is running at a speed of 96kmph. What distance will it cover in 14sec? Options: A:378m B:350m C:380m D:200m E:250m A: Reasoning process: 1. We are given that the car is running at a speed of 96 km per hour. 2. We want to \ufb01nd the distance it will cover in 14 seconds. 3. We need to convert both km and hours to meters and seconds in order to compare them. 4. 1 hour has 60 minutes, 1 minute has 60 seconds, so 1 hour has 3600 seconds. 5. 1 km has 1000 meters, so 96 km have 96*1000 = 96000 meters. 6. Since we are given the speed of the car in km per hour, we need to divide the total distance in meters by the total time in seconds to \ufb01nd the distance in meters per second. 7. So, the distance the car will cover in 14 seconds is 96000 meters / 3600 seconds/hour * 14 seconds = 378.89 meters. Final answer: The distance the car will cover in 14 seconds is [A]378m. Final answer: A.\n\nTable 18: The exemplars are selected on AQuA train set.\n\n28\n\nDATASET\n\nCSQA\n\nIter-CoT(S) Exemplars\n\nQ: Where can peanut butter be stored? Choices: A.container B.supermarket C.pantry D.sandwich E.jar A: Reasoning process: 1. Peanut butter is a food item. 2. Food items are usually stored in a place where they can stay fresh, like a refrigerator or a pantry. 3. A pantry is a good option for storing food items that don\u2019t need to be refrigerated, like peanut butter. Final answer: C.\n\nQ: He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? Choices: A.country club B.rich person\u2019s house C.pool D.park E.\ufb01tness center A: Reasoning process: The person is waiting at a squash court, so they are likely at a sports facility or gym. Out of the options given, the only option that seems like it could be at the other end of a public place is a park. Final answer: D.\n\nQ: What do people want to do when they love a place that they are going on vacation in? Choices: A.pleasant thoughts B.overspending C.moving there D.staying there E.debt A: Reasoning process: 1. People want to do something when they love a place that they are going on vacation in. 2. The options given are A. pleasant thoughts, B. overspending, C. moving there, D. staying there, and E. debt. 3. Out of these options, the only one that makes sense as something people might want to do when they love a place is D. staying there. Final answer: D. Tao Yu, Chien-Sheng Wu, Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Dragomir R Radev, Richard Socher, and Caiming Xiong. 2021. Grappa: Grammar-augmented pre-training for table semantic parsing. In ICLR.\n\nTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingn- ing Yao, Shanelle Roman, et al. 2018. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. In Proceedings of the 2018 Conference on Empiri- cal Methods in Natural Language Processing, pages 3911\u20133921.\n\nHongzhi Zhang, Yingyao Wang, Sirui Wang, Xuezhi Cao, Fuzheng Zhang, and Zhongyuan Wang. 2020. Table fact veri\ufb01cation with structure-aware trans- former. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1624\u20131629.\n\nYuchen Zhang, Panupong Pasupat, and Percy Liang. 2017. Macro grammars and holistic triggering for ef- \ufb01cient semantic parsing. In Proceedings of the 2017 Conference on Empirical Methods in Natural Lan- guage Processing, pages 1214\u20131223.\n\nVictor Zhong, Caiming Xiong, and Richard Socher. 2017. Seq2sql: Generating structured queries from natural language using reinforcement learning. arXiv preprint arXiv:1709.00103.\n\nWanjun Zhong, Duyu Tang, Zhangyin Feng, Nan Duan, Ming Zhou, Ming Gong, Linjun Shou, Daxin Jiang, Jiahai Wang, and Jian Yin. 2020. Logical- factchecker: Leveraging logical operations for fact checking with graph module network. In Proceed- ings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 6053\u20136065."
        ]
    },
    {
        "seed": "Research the various prompting techniques and find a unique connection between them. Generate an abstract for a research paper from your findings.",
        "summaries": [
            "Query: What are the main findings of the study \"A Prompt Log Analysis of Text-to-Image Generation Systems\" by Yutong Xie et al.?\n\nUnfortunately, the main findings of the study \"A Prompt Log Analysis of Text-to-Image Generation Systems\" by Yutong Xie et al. are not provided in the given information. To obtain the main findings of the study, it would be necessary to access the full paper or any available summaries or abstracts of the study.\n\nQuery: How do the images with high aesthetic appeal differ from the images with low aesthetic appeal in terms of visual characteristics?\n\nThe given information does not provide specific details about the visual characteristics that differentiate images with high aesthetic appeal from those with low aesthetic appeal. To answer this query, it would be necessary to refer to a study or research that specifically investigates the visual characteristics associated with aesthetic appeal in images.\n\nQuery: Can you provide more information about the research conducted by Mark Weiser in his paper \"Some Computer Science Issues in Ubiquitous Computing\"?\n\nThe paper \"Some Computer Science Issues in Ubiquitous Computing\" by Mark Weiser was published in the Communications of the ACM journal in July 1993. The paper discusses the concept of ubiquitous computing, which refers to the integration of computing devices and technologies into everyday objects and environments. Weiser explores the challenges and opportunities presented by ubiquitous computing, including issues related to privacy, security, system design, and human-computer interaction. The paper is considered a seminal work in the field of ubiquitous computing and has had a significant impact on subsequent research and development in this area.\n\nQuery: What are the key insights from the investigation on minimum text lengths for lexical diversity indices conducted by Fred Zenker and Kristopher Kyle?\n\nThe given information does not provide specific details about the key insights from the investigation on minimum text lengths for lexical diversity indices conducted by Fred Zenker and Kristopher Kyle. To obtain the key insights from this investigation, it would be necessary to access the full research paper or any available summaries or abstracts of the study.\n\nQuery: How does the book \"AI Art: Machine Visions and Warped Dreams\" by Joanna Zylinska explore the intersection of artificial intelligence and art?\n\nThe book \"AI Art: Machine Visions and Warped Dreams\" by Joanna Zylinska explores the intersection of artificial intelligence and art. It delves into the ways in which AI technologies are being used in artistic practices and examines the implications and challenges that arise from this intersection. The book critically engages with questions about creativity, authorship, aesthetics, and the role of the artist in the context of AI-generated art. It also explores the ethical and philosophical dimensions of AI art, considering issues such as bias, agency, and the impact of AI on artistic production and reception. The book provides a comprehensive analysis of the complex relationship between artificial intelligence and art, offering insights into the potential future directions of AI in the art world."
        ],
        "raw": [
            "[55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per"
        ]
    },
    {
        "seed": "What are some unique ways various prompting techniques can be combined? Share a detailed example.",
        "summaries": [
            "The abstract provided does not directly discuss the topic of \"Unique ways to combine prompting techniques.\" However, it does provide some relevant information that can be used to inform our understanding of the topic.\n\nFrom the abstract, we can gather that there are studies and research papers related to text-to-image generation systems, lexical diversity indices, AI art, and human-computer interaction. These topics may provide insights into different prompting techniques and their applications.\n\nTo further explore unique ways to combine prompting techniques, it would be beneficial to review the specific studies and research papers mentioned in the abstract, such as:\n\n- [56] \"A Prompt Log Analysis of Text-to-Image Generation Systems\" by Yutong Xie et al. This paper likely discusses different prompts used in text-to-image generation systems and their effectiveness in producing desired outputs.\n\n- [57] \"Investigating minimum text lengths for lexical diversity indices\" by Fred Zenker and Kristopher Kyle. This paper may explore how different prompt lengths can impact the lexical diversity of generated text.\n\n- [58] \"AI Art: Machine Visions and Warped Dreams\" by Joanna Zylinska. This book may provide insights into the intersection of AI and art, including how prompts can be used to guide the creation of AI-generated art.\n\nBy delving into these specific sources, we can gain a deeper understanding of the subject matter and potentially identify unique ways to combine prompting techniques."
        ],
        "raw": [
            "[55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per aesthetics/ [Accessed Nov. 11, 2022].\n\n[52] Ben Shneiderman. 2020. Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal\n\nof Human\u2013Computer Interaction 36, 6 (2020), 495\u2013504. https://doi.org/10.1080/10447318.2020.1741118\n\n[53] Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. 2022. Make-A-Video: Text-to-Video Generation without Text- Video Data. (2022). https://doi.org/10.48550/ARXIV.2209.14792 [Preprint]. Available at: https://arxiv.org/abs/2209.14792 [Accessed Nov. 14, 2022]..\n\n[54] Ethan Smith. 2022. A Traveler\u2019s Guide to the Latent Space. (2022). https://sweet-hall-e72.notion.site/A-Traveler-s-\n\nGuide-to-the-Latent-Space-85efba7e5e6a40e5bd3cae980f30235f [Accessed Nov. 9, 2022].\n\n[55] Charlie Snell. 2021. Alien Dreams: An Emerging Art Scene. (2021). https://ml.berkeley.edu/blog/posts/clip-art/\n\n[Accessed Nov. 9, 2022].\n\n[56] Ruben Villegas, Mohammad Babaeizadeh, Pieter-Jan Kindermans, Hernan Moraldo, Han Zhang, Mohammad Taghi Saffar, Santiago Castro, Julius Kunze, and Dumitru Erhan. 2022. Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions. (2022). https://openreview.net/forum?id=vOEXS39nOF [Accessed Nov. 14, 2022]. [57] Zijie J. Wang, Evan Montoya, David Munechika, Haoyang Yang, Benjamin Hoover, and Duen Horng Chau. 2022. DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (2022). https://doi.org/10. 48550/ARXIV.2210.14896 [Preprint]. Available at: https://arxiv.org/abs/2210.14896 [Accessed Nov. 9, 2022]..\n\n[58] Jacob O. Wobbrock and Julie A. Kientz. 2016. Research Contributions in Human-Computer Interaction. Interactions 23,\n\n3 (2016), 38\u201344. https://doi.org/10.1145/2907069\n\n[59] Wojciech Zaremba and Greg Brockman. 2021. OpenAI Codex. (2021). https://openai.com/blog/openai-codex [Accessed\n\nNov. 9, 2022].\n\n18\n\nJonas Oppenlaender\n\n[60] Lisai Zhang, Qingcai Chen, Baotian Hu, and Shuoran Jiang. 2020. Text-Guided Neural Image Inpainting. Association\n\nfor Computing Machinery, New York, NY, 1302\u20131310. https://doi.org/10.1145/3394171.3414017 [23] Y. Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis, H. Chan, and J. Ba, \u201cLarge language models are human-level prompt engineers,\u201d 2022. [Online]. Available: https://arxiv.org/abs/2211.01910\n\n[24] T. Shin, Y. Razeghi, R. L. L.\n\nIV, E. Wallace, and S. Singh, from language models with \u201cAutoprompt: Eliciting knowledge automatically generated prompts,\u201d CoRR, vol. abs/2010.15980, 2020. [Online]. Available: https://arxiv.org/abs/2010.15980\n\n[25] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever,\n\n\u201cLanguage models are unsupervised multitask learners,\u201d 2019.\n\n[26] D. Zhou, N. Sch\u00a8arli, L. Hou,\n\nJ. Wei, N. Scales, X. Wang, D. Schuurmans, C. Cui, O. Bousquet, Q. Le, and E. Chi, \u201cLeast-to- most prompting enables complex reasoning in large language models,\u201d 2022. [Online]. Available: https://arxiv.org/abs/2205.10625\n\n[27] J. Jung, L. Qin, S. Welleck, F. Brahman, C. Bhagavatula, R. L. \u201cMaieutic prompting: Logically consistent [Online]. Available:\n\nBras, reasoning with recursive explanations,\u201d 2022. https://arxiv.org/abs/2205.11822\n\nand Y. Choi,\n\n[28] S. Arora, A. Narayan, M.\n\nI. Chami,\n\nF. Chen, L. Orr, N. Guha, K. Bhatia, anything: A and C. Re, simple strategy for prompting language models,\u201d in International Conference on Learning Representations, 2023. [Online]. Available: https://openreview.net/forum?id=bhUPJnS2g0X\n\n\u201cAsk me\n\n[29] V. Liu and L. B. Chilton, \u201cDesign guidelines for prompt engineering text-to-image generative models,\u201d in Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems, 2022, pp. 1\u201323. [30] P. Maddigan and T. Susnjak, \u201cChat2vis: Generating data visualisations via natural language using chatgpt, codex and gpt-3 large language models,\u201d arXiv preprint arXiv:2302.02094, 2023.\n\n[31] X. Han, W. Zhao, N. Ding, Z. Liu, and M. Sun, \u201cPtr: Prompt tuning with rules for text classi\ufb01cation,\u201d AI Open, vol. 3, pp. 182\u2013192, 2022. [55] Mark Weiser. 1993. Some Computer Science Issues in Ubiquitous Computing. Commun. ACM 36, 7 (jul 1993), 75\u201384.\n\nhttps://doi.org/10.1145/159544.159617\n\n[56] Yutong Xie, Zhaoying Pan, Jinge Ma, Luo Jie, and Qiaozhu Mei. 2023. A Prompt Log Analysis of Text-to-Image\n\nGeneration Systems. In Proceedings of the ACM Web Conference (WWW \u201923).\n\n[57] Fred Zenker and Kristopher Kyle. 2021. Investigating minimum text lengths for lexical diversity indices. Assessing\n\nWriting 47 (2021), 15 pages. https://doi.org/10.1016/j.asw.2020.100505\n\n[58] Joanna Zylinska. 2020. AI Art: Machine Visions and Warped Dreams. Open Humanities Press, London, UK.\n\nA SET OF IMAGES USED IN STUDY 1\n\nA.1 Images with High Aesthetic Appeal\n\n27\n\nH1: the foundations of ori- gin, matte painting, genesis, trending on artstation, high resolution\n\nH4: eclectic interior of the mind\n\nH5: , ., ., matte painting, 8k cgsociety\n\nH6: The Dude by Glenn Fabry\n\nH2: vikings. by Dan Mumford, matte painting, Studio Ghibli\n\nH7: fantastic wardrobe of the inner sanctuary comes to life in giant birta- tion of the soul\n\nH9: tidal wave, matte painting, ren- dered in octane, ghibli, 8k #epic #wow trending on wikiart\n\nH8: a moment of silence for our fallen heroes. War memorial. central. CGSoci- ety, painting, postprocessing\n\nH10: portrait of a world war soldier on artstation\n\nH3: buck, Hudson River School\n\n28\n\nJ. Oppenlaender et al.\n\nA.2 Images with Low Aesthetic Appeal\n\nL1: Multi-Fidelity Met- aLearning for Efficient and Robust AutoDL\n\nL2: a tweet about bias\n\nL3: Asterix at the Robot Games. by Rene Goscinny and Albert Uderzo\n\nL4: amazing green screen ef- fect\n\nL5: Office Space, Bill Lum- bergh. \u201cyeah, we need you to come in on Saturday, mkay?\u201d\n\nL6: Blind No. 20, Seventeen- foot high Ceiling or Lower, Historical Veridian Green, Indian Yellow Hue, Hansa Yellow Medium (to Mike Kelley)\n\nL7: we can do it! propa- ganda poster\n\nL8: My New Band Is Called Syskill\n\nL9: China buys Russia\n\nL10: artwork, academic pa- per"
        ]
    }
]